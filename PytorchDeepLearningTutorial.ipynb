{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traning an Image Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "testset = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"plane\", \"car\", \"birds\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " deer plane  ship   car\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "    \n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print(\" \".join(\"%5s\" % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2):\n",
    "    running_loss = 0.0\n",
    "    for i, data in tqdm(enumerate(trainloader, 0), total=len(trainloader)):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:\n",
    "            print(\"[%d, %5d] loss: %.3f\" % (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"./cifar_net.pth\"\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print(\"GroundTruth: \", \" \".join(\"%5s\" % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))\n",
    "outputs = net(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "print(\"Predicted: \", \" \".join(\"%5s\" % classes[predicted[j]] for j in range(4)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "print(100 * correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "            \n",
    "for i in range(10):\n",
    "    print(classes[i], 100 * class_correct[i] / class_total[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda: 0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_gpu = Net()\n",
    "optimizer = optim.SGD(net_gpu.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_gpu.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net_gpu.zero_grad()\n",
    "optimizer.zero_grad()\n",
    "for epoch in range(2):\n",
    "    running_loss = 0.0\n",
    "    for i, data in tqdm(enumerate(trainloader, 0), total=len(trainloader)):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net_gpu(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:\n",
    "            print(\"[%d, %5d] loss: %.3f\" % (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net_gpu(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "print(100 * correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.randn(3, 1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "trainset = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "testset = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 20, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(20, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda: 0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net_gpu = Net()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net_gpu.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "net_gpu.to(device)\n",
    "\n",
    "net_gpu.zero_grad()\n",
    "optimizer.zero_grad()\n",
    "\n",
    "is_running_loss_increased = False\n",
    "prev_running_loss = float(\"inf\")\n",
    "epoch = 0\n",
    "running_loss_avgs = []\n",
    "training_errors = []\n",
    "loss_all = []\n",
    "while(1):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net_gpu(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        loss_all.append(loss.item())\n",
    "        total += labels.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        if i % 2000 == 1999:\n",
    "            running_loss_avg = running_loss / 2000\n",
    "            training_error = 100 * (total - correct) / total\n",
    "            print(\"[%d, %5d] loss: %.3f training error %.3f\" \n",
    "                  % (epoch + 1, i + 1, running_loss_avg, training_error))\n",
    "            running_loss_avgs.append(running_loss_avg)\n",
    "            training_errors.append(training_error)\n",
    "            \n",
    "            if prev_running_loss < running_loss:\n",
    "                is_running_loss_increased = True\n",
    "                break\n",
    "            prev_running_loss = running_loss\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            running_loss = 0.0\n",
    "    if is_running_loss_increased:\n",
    "        print(f\"Tranining Done at Epoch: {epoch}\")\n",
    "        break\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Training Error\")\n",
    "plt.plot(training_errors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net_gpu(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "print(100 * correct / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transforms_train = transforms.Compose([\n",
    "  transforms.RandomCrop(32, padding=4),\n",
    "  transforms.RandomHorizontalFlip(),\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "transforms_test = transforms.Compose([\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "trainset = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transforms_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=4)\n",
    "testset = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transforms_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model structure referred\n",
    "# from https://github.com/kuangliu/pytorch-cifar/blob/master/models/resnet.py\n",
    "\n",
    "cfg = [64, 64, \"P\", 128, 128, \"P\", 256, 256, 256, 256, \"P\", 512, 512, 512, 512, \"P\", 512, 512, 512, 512, \"P\"]\n",
    "\n",
    "class VGG19(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(VGG19, self).__init__()\n",
    "        self.layers = self._make_layers(cfg)\n",
    "        self.fc = nn.Sequential(*[\n",
    "            nn.Linear(512, 10)\n",
    "        ])\n",
    "#         self.fc = nn.Sequential(*[\n",
    "#             nn.Dropout(),\n",
    "#             nn.Linear(512, 4096),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Dropout(),\n",
    "#             nn.Linear(4096, 4096),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Linear(4096, 10)\n",
    "#         ])\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == \"P\":\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels=in_channels, out_channels=x, kernel_size=3, padding=1),\n",
    "                          nn.BatchNorm2d(x),\n",
    "                          nn.ReLU(inplace=True)]\n",
    "                in_channels = x\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of parameters of model is 20040522\n",
      "train epoch : 1 [390/391]| loss: 2.636 | acc: 10.086\n",
      "test epoch : 1 [78/79]| loss: 2.315 | acc: 10.670\n",
      "best test accuracy is  10.67\n",
      "train epoch : 2 [390/391]| loss: 2.301 | acc: 10.468\n",
      "test epoch : 2 [78/79]| loss: 2.301 | acc: 10.790\n",
      "best test accuracy is  10.79\n",
      "train epoch : 3 [390/391]| loss: 2.293 | acc: 11.570\n",
      "test epoch : 3 [78/79]| loss: 2.256 | acc: 15.670\n",
      "best test accuracy is  15.67\n",
      "train epoch : 4 [390/391]| loss: 2.035 | acc: 19.834\n",
      "test epoch : 4 [78/79]| loss: 1.882 | acc: 22.620\n",
      "best test accuracy is  22.62\n",
      "train epoch : 5 [390/391]| loss: 1.867 | acc: 24.602\n",
      "test epoch : 5 [78/79]| loss: 1.786 | acc: 27.960\n",
      "best test accuracy is  27.96\n",
      "train epoch : 6 [390/391]| loss: 1.772 | acc: 29.248\n",
      "test epoch : 6 [78/79]| loss: 1.876 | acc: 28.730\n",
      "best test accuracy is  28.73\n",
      "train epoch : 7 [390/391]| loss: 1.566 | acc: 38.736\n",
      "test epoch : 7 [78/79]| loss: 1.637 | acc: 37.420\n",
      "best test accuracy is  37.42\n",
      "train epoch : 8 [390/391]| loss: 1.357 | acc: 49.454\n",
      "test epoch : 8 [78/79]| loss: 1.261 | acc: 54.390\n",
      "best test accuracy is  54.39\n",
      "train epoch : 9 [390/391]| loss: 1.159 | acc: 58.368\n",
      "test epoch : 9 [78/79]| loss: 1.897 | acc: 49.980\n",
      "best test accuracy is  54.39\n",
      "train epoch : 10 [390/391]| loss: 1.018 | acc: 64.516\n",
      "test epoch : 10 [78/79]| loss: 1.010 | acc: 66.170\n",
      "best test accuracy is  66.17\n",
      "train epoch : 11 [390/391]| loss: 0.896 | acc: 68.880\n",
      "test epoch : 11 [78/79]| loss: 0.979 | acc: 67.780\n",
      "best test accuracy is  67.78\n",
      "train epoch : 12 [390/391]| loss: 0.800 | acc: 72.952\n",
      "test epoch : 12 [78/79]| loss: 0.928 | acc: 70.310\n",
      "best test accuracy is  70.31\n",
      "train epoch : 13 [390/391]| loss: 0.746 | acc: 75.266\n",
      "test epoch : 13 [78/79]| loss: 0.752 | acc: 75.640\n",
      "best test accuracy is  75.64\n",
      "train epoch : 14 [390/391]| loss: 0.679 | acc: 77.676\n",
      "test epoch : 14 [78/79]| loss: 0.998 | acc: 71.850\n",
      "best test accuracy is  75.64\n",
      "train epoch : 15 [390/391]| loss: 0.626 | acc: 79.590\n",
      "test epoch : 15 [78/79]| loss: 0.657 | acc: 78.780\n",
      "best test accuracy is  78.78\n",
      "train epoch : 16 [390/391]| loss: 0.578 | acc: 81.174\n",
      "test epoch : 16 [78/79]| loss: 0.650 | acc: 79.350\n",
      "best test accuracy is  79.35\n",
      "train epoch : 17 [390/391]| loss: 0.533 | acc: 82.708\n",
      "test epoch : 17 [78/79]| loss: 0.615 | acc: 80.530\n",
      "best test accuracy is  80.53\n",
      "train epoch : 18 [390/391]| loss: 0.502 | acc: 83.778\n",
      "test epoch : 18 [78/79]| loss: 0.585 | acc: 80.950\n",
      "best test accuracy is  80.95\n",
      "train epoch : 19 [390/391]| loss: 0.478 | acc: 84.378\n",
      "test epoch : 19 [78/79]| loss: 0.572 | acc: 81.500\n",
      "best test accuracy is  81.5\n",
      "train epoch : 20 [390/391]| loss: 0.448 | acc: 85.534\n",
      "test epoch : 20 [78/79]| loss: 0.570 | acc: 81.660\n",
      "best test accuracy is  81.66\n",
      "train epoch : 21 [390/391]| loss: 0.440 | acc: 85.866\n",
      "test epoch : 21 [78/79]| loss: 0.646 | acc: 80.320\n",
      "best test accuracy is  81.66\n",
      "train epoch : 22 [390/391]| loss: 0.412 | acc: 86.544\n",
      "test epoch : 22 [78/79]| loss: 0.518 | acc: 84.040\n",
      "best test accuracy is  84.04\n",
      "train epoch : 23 [390/391]| loss: 0.392 | acc: 87.290\n",
      "test epoch : 23 [78/79]| loss: 0.563 | acc: 82.440\n",
      "best test accuracy is  84.04\n",
      "train epoch : 24 [390/391]| loss: 0.384 | acc: 87.626\n",
      "test epoch : 24 [78/79]| loss: 0.462 | acc: 84.930\n",
      "best test accuracy is  84.93\n",
      "train epoch : 25 [390/391]| loss: 0.370 | acc: 88.126\n",
      "test epoch : 25 [78/79]| loss: 0.454 | acc: 85.720\n",
      "best test accuracy is  85.72\n",
      "train epoch : 26 [390/391]| loss: 0.354 | acc: 88.698\n",
      "test epoch : 26 [78/79]| loss: 0.475 | acc: 84.580\n",
      "best test accuracy is  85.72\n",
      "train epoch : 27 [390/391]| loss: 0.341 | acc: 88.902\n",
      "test epoch : 27 [78/79]| loss: 0.643 | acc: 80.130\n",
      "best test accuracy is  85.72\n",
      "train epoch : 28 [390/391]| loss: 0.337 | acc: 89.118\n",
      "test epoch : 28 [78/79]| loss: 0.456 | acc: 85.790\n",
      "best test accuracy is  85.79\n",
      "train epoch : 29 [390/391]| loss: 0.323 | acc: 89.622\n",
      "test epoch : 29 [78/79]| loss: 0.488 | acc: 84.870\n",
      "best test accuracy is  85.79\n",
      "train epoch : 30 [390/391]| loss: 0.318 | acc: 89.616\n",
      "test epoch : 30 [78/79]| loss: 0.677 | acc: 80.070\n",
      "best test accuracy is  85.79\n",
      "train epoch : 31 [390/391]| loss: 0.301 | acc: 90.104\n",
      "test epoch : 31 [78/79]| loss: 0.453 | acc: 85.720\n",
      "best test accuracy is  85.79\n",
      "train epoch : 32 [390/391]| loss: 0.301 | acc: 90.232\n",
      "test epoch : 32 [78/79]| loss: 0.398 | acc: 87.460\n",
      "best test accuracy is  87.46\n",
      "train epoch : 33 [390/391]| loss: 0.291 | acc: 90.436\n",
      "test epoch : 33 [78/79]| loss: 0.479 | acc: 85.920\n",
      "best test accuracy is  87.46\n",
      "train epoch : 34 [390/391]| loss: 0.272 | acc: 91.184\n",
      "test epoch : 34 [78/79]| loss: 0.478 | acc: 85.240\n",
      "best test accuracy is  87.46\n",
      "train epoch : 35 [390/391]| loss: 0.273 | acc: 91.040\n",
      "test epoch : 35 [78/79]| loss: 0.497 | acc: 85.330\n",
      "best test accuracy is  87.46\n",
      "train epoch : 36 [390/391]| loss: 0.265 | acc: 91.304\n",
      "test epoch : 36 [78/79]| loss: 0.495 | acc: 84.950\n",
      "best test accuracy is  87.46\n",
      "train epoch : 37 [390/391]| loss: 0.252 | acc: 91.822\n",
      "test epoch : 37 [78/79]| loss: 0.446 | acc: 86.220\n",
      "best test accuracy is  87.46\n",
      "train epoch : 38 [390/391]| loss: 0.250 | acc: 91.872\n",
      "test epoch : 38 [78/79]| loss: 0.436 | acc: 87.020\n",
      "best test accuracy is  87.46\n",
      "train epoch : 39 [390/391]| loss: 0.241 | acc: 92.130\n",
      "test epoch : 39 [78/79]| loss: 0.514 | acc: 85.210\n",
      "best test accuracy is  87.46\n",
      "train epoch : 40 [390/391]| loss: 0.241 | acc: 92.072\n",
      "test epoch : 40 [78/79]| loss: 0.486 | acc: 85.980\n",
      "best test accuracy is  87.46\n",
      "train epoch : 41 [390/391]| loss: 0.241 | acc: 92.148\n",
      "test epoch : 41 [78/79]| loss: 0.428 | acc: 86.960\n",
      "best test accuracy is  87.46\n",
      "train epoch : 42 [390/391]| loss: 0.231 | acc: 92.364\n",
      "test epoch : 42 [78/79]| loss: 0.393 | acc: 87.750\n",
      "best test accuracy is  87.75\n",
      "train epoch : 43 [390/391]| loss: 0.224 | acc: 92.604\n",
      "test epoch : 43 [78/79]| loss: 0.399 | acc: 87.840\n",
      "best test accuracy is  87.84\n",
      "train epoch : 44 [390/391]| loss: 0.228 | acc: 92.574\n",
      "test epoch : 44 [78/79]| loss: 0.474 | acc: 86.470\n",
      "best test accuracy is  87.84\n",
      "train epoch : 45 [390/391]| loss: 0.217 | acc: 92.816\n",
      "test epoch : 45 [78/79]| loss: 0.442 | acc: 87.270\n",
      "best test accuracy is  87.84\n",
      "train epoch : 46 [390/391]| loss: 0.211 | acc: 93.138\n",
      "test epoch : 46 [78/79]| loss: 0.415 | acc: 88.160\n",
      "best test accuracy is  88.16\n",
      "train epoch : 47 [390/391]| loss: 0.207 | acc: 93.146\n",
      "test epoch : 47 [78/79]| loss: 0.556 | acc: 84.170\n",
      "best test accuracy is  88.16\n",
      "train epoch : 48 [390/391]| loss: 0.209 | acc: 93.066\n",
      "test epoch : 48 [78/79]| loss: 0.399 | acc: 88.180\n",
      "best test accuracy is  88.18\n",
      "train epoch : 49 [390/391]| loss: 0.205 | acc: 93.372\n",
      "test epoch : 49 [78/79]| loss: 0.453 | acc: 86.790\n",
      "best test accuracy is  88.18\n",
      "train epoch : 50 [390/391]| loss: 0.200 | acc: 93.468\n",
      "test epoch : 50 [78/79]| loss: 0.483 | acc: 86.070\n",
      "best test accuracy is  88.18\n",
      "train epoch : 51 [390/391]| loss: 0.195 | acc: 93.538\n",
      "test epoch : 51 [78/79]| loss: 0.466 | acc: 86.420\n",
      "best test accuracy is  88.18\n",
      "train epoch : 52 [390/391]| loss: 0.194 | acc: 93.630\n",
      "test epoch : 52 [78/79]| loss: 0.386 | acc: 88.690\n",
      "best test accuracy is  88.69\n",
      "train epoch : 53 [390/391]| loss: 0.190 | acc: 93.720\n",
      "test epoch : 53 [78/79]| loss: 0.409 | acc: 88.510\n",
      "best test accuracy is  88.69\n",
      "train epoch : 54 [390/391]| loss: 0.193 | acc: 93.600\n",
      "test epoch : 54 [78/79]| loss: 0.469 | acc: 86.700\n",
      "best test accuracy is  88.69\n",
      "train epoch : 55 [390/391]| loss: 0.194 | acc: 93.546\n",
      "test epoch : 55 [78/79]| loss: 0.516 | acc: 85.020\n",
      "best test accuracy is  88.69\n",
      "train epoch : 56 [390/391]| loss: 0.188 | acc: 93.706\n",
      "test epoch : 56 [78/79]| loss: 0.419 | acc: 87.750\n",
      "best test accuracy is  88.69\n",
      "train epoch : 57 [390/391]| loss: 0.187 | acc: 93.824\n",
      "test epoch : 57 [78/79]| loss: 0.407 | acc: 87.820\n",
      "best test accuracy is  88.69\n",
      "train epoch : 58 [390/391]| loss: 0.174 | acc: 94.200\n",
      "test epoch : 58 [78/79]| loss: 0.527 | acc: 85.540\n",
      "best test accuracy is  88.69\n",
      "train epoch : 59 [390/391]| loss: 0.182 | acc: 94.118\n",
      "test epoch : 59 [78/79]| loss: 0.409 | acc: 88.120\n",
      "best test accuracy is  88.69\n",
      "train epoch : 60 [390/391]| loss: 0.179 | acc: 94.140\n",
      "test epoch : 60 [78/79]| loss: 0.412 | acc: 88.310\n",
      "best test accuracy is  88.69\n",
      "train epoch : 61 [390/391]| loss: 0.177 | acc: 94.184\n",
      "test epoch : 61 [78/79]| loss: 0.448 | acc: 86.930\n",
      "best test accuracy is  88.69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 62 [390/391]| loss: 0.174 | acc: 94.290\n",
      "test epoch : 62 [78/79]| loss: 0.401 | acc: 87.530\n",
      "best test accuracy is  88.69\n",
      "train epoch : 63 [390/391]| loss: 0.174 | acc: 94.318\n",
      "test epoch : 63 [78/79]| loss: 0.416 | acc: 87.880\n",
      "best test accuracy is  88.69\n",
      "train epoch : 64 [390/391]| loss: 0.175 | acc: 94.402\n",
      "test epoch : 64 [78/79]| loss: 0.460 | acc: 86.720\n",
      "best test accuracy is  88.69\n",
      "train epoch : 65 [390/391]| loss: 0.169 | acc: 94.590\n",
      "test epoch : 65 [78/79]| loss: 0.411 | acc: 87.700\n",
      "best test accuracy is  88.69\n",
      "train epoch : 66 [390/391]| loss: 0.169 | acc: 94.388\n",
      "test epoch : 66 [78/79]| loss: 0.574 | acc: 84.280\n",
      "best test accuracy is  88.69\n",
      "train epoch : 67 [390/391]| loss: 0.162 | acc: 94.676\n",
      "test epoch : 67 [78/79]| loss: 0.473 | acc: 87.200\n",
      "best test accuracy is  88.69\n",
      "train epoch : 68 [390/391]| loss: 0.167 | acc: 94.500\n",
      "test epoch : 68 [78/79]| loss: 0.406 | acc: 88.270\n",
      "best test accuracy is  88.69\n",
      "train epoch : 69 [390/391]| loss: 0.169 | acc: 94.576\n",
      "test epoch : 69 [78/79]| loss: 0.414 | acc: 87.590\n",
      "best test accuracy is  88.69\n",
      "train epoch : 70 [390/391]| loss: 0.171 | acc: 94.424\n",
      "test epoch : 70 [78/79]| loss: 0.411 | acc: 87.730\n",
      "best test accuracy is  88.69\n",
      "train epoch : 71 [390/391]| loss: 0.163 | acc: 94.652\n",
      "test epoch : 71 [78/79]| loss: 0.365 | acc: 89.350\n",
      "best test accuracy is  89.35\n",
      "train epoch : 72 [390/391]| loss: 0.161 | acc: 94.716\n",
      "test epoch : 72 [78/79]| loss: 0.505 | acc: 85.980\n",
      "best test accuracy is  89.35\n",
      "train epoch : 73 [390/391]| loss: 0.157 | acc: 94.834\n",
      "test epoch : 73 [78/79]| loss: 0.366 | acc: 89.680\n",
      "best test accuracy is  89.68\n",
      "train epoch : 74 [390/391]| loss: 0.156 | acc: 94.772\n",
      "test epoch : 74 [78/79]| loss: 0.392 | acc: 88.610\n",
      "best test accuracy is  89.68\n",
      "train epoch : 75 [390/391]| loss: 0.160 | acc: 94.754\n",
      "test epoch : 75 [78/79]| loss: 0.391 | acc: 88.770\n",
      "best test accuracy is  89.68\n",
      "train epoch : 76 [390/391]| loss: 0.154 | acc: 94.956\n",
      "test epoch : 76 [78/79]| loss: 0.663 | acc: 83.230\n",
      "best test accuracy is  89.68\n",
      "train epoch : 77 [390/391]| loss: 0.156 | acc: 94.820\n",
      "test epoch : 77 [78/79]| loss: 0.378 | acc: 88.700\n",
      "best test accuracy is  89.68\n",
      "train epoch : 78 [390/391]| loss: 0.156 | acc: 94.836\n",
      "test epoch : 78 [78/79]| loss: 0.468 | acc: 86.900\n",
      "best test accuracy is  89.68\n",
      "train epoch : 79 [390/391]| loss: 0.156 | acc: 94.894\n",
      "test epoch : 79 [78/79]| loss: 0.419 | acc: 88.210\n",
      "best test accuracy is  89.68\n",
      "train epoch : 80 [390/391]| loss: 0.152 | acc: 94.984\n",
      "test epoch : 80 [78/79]| loss: 0.414 | acc: 88.570\n",
      "best test accuracy is  89.68\n",
      "train epoch : 81 [390/391]| loss: 0.155 | acc: 94.788\n",
      "test epoch : 81 [78/79]| loss: 0.465 | acc: 87.340\n",
      "best test accuracy is  89.68\n",
      "train epoch : 82 [390/391]| loss: 0.152 | acc: 94.896\n",
      "test epoch : 82 [78/79]| loss: 0.420 | acc: 87.560\n",
      "best test accuracy is  89.68\n",
      "train epoch : 83 [390/391]| loss: 0.151 | acc: 95.122\n",
      "test epoch : 83 [78/79]| loss: 0.491 | acc: 86.220\n",
      "best test accuracy is  89.68\n",
      "train epoch : 84 [390/391]| loss: 0.152 | acc: 94.956\n",
      "test epoch : 84 [78/79]| loss: 0.420 | acc: 88.430\n",
      "best test accuracy is  89.68\n",
      "train epoch : 85 [390/391]| loss: 0.150 | acc: 95.010\n",
      "test epoch : 85 [78/79]| loss: 0.558 | acc: 85.480\n",
      "best test accuracy is  89.68\n",
      "train epoch : 86 [390/391]| loss: 0.149 | acc: 95.048\n",
      "test epoch : 86 [78/79]| loss: 0.406 | acc: 88.660\n",
      "best test accuracy is  89.68\n",
      "train epoch : 87 [390/391]| loss: 0.152 | acc: 94.962\n",
      "test epoch : 87 [78/79]| loss: 0.406 | acc: 88.010\n",
      "best test accuracy is  89.68\n",
      "train epoch : 88 [390/391]| loss: 0.145 | acc: 95.192\n",
      "test epoch : 88 [78/79]| loss: 0.383 | acc: 89.280\n",
      "best test accuracy is  89.68\n",
      "train epoch : 89 [390/391]| loss: 0.141 | acc: 95.380\n",
      "test epoch : 89 [78/79]| loss: 0.474 | acc: 86.760\n",
      "best test accuracy is  89.68\n",
      "train epoch : 90 [390/391]| loss: 0.148 | acc: 95.150\n",
      "test epoch : 90 [78/79]| loss: 0.501 | acc: 87.370\n",
      "best test accuracy is  89.68\n",
      "train epoch : 91 [390/391]| loss: 0.146 | acc: 95.092\n",
      "test epoch : 91 [78/79]| loss: 0.577 | acc: 84.410\n",
      "best test accuracy is  89.68\n",
      "train epoch : 92 [390/391]| loss: 0.150 | acc: 95.076\n",
      "test epoch : 92 [78/79]| loss: 0.517 | acc: 85.910\n",
      "best test accuracy is  89.68\n",
      "train epoch : 93 [390/391]| loss: 0.147 | acc: 95.266\n",
      "test epoch : 93 [78/79]| loss: 0.471 | acc: 87.110\n",
      "best test accuracy is  89.68\n",
      "train epoch : 94 [390/391]| loss: 0.146 | acc: 95.194\n",
      "test epoch : 94 [78/79]| loss: 0.500 | acc: 86.610\n",
      "best test accuracy is  89.68\n",
      "train epoch : 95 [390/391]| loss: 0.140 | acc: 95.420\n",
      "test epoch : 95 [78/79]| loss: 0.481 | acc: 87.630\n",
      "best test accuracy is  89.68\n",
      "train epoch : 96 [390/391]| loss: 0.146 | acc: 95.116\n",
      "test epoch : 96 [78/79]| loss: 0.405 | acc: 88.450\n",
      "best test accuracy is  89.68\n",
      "train epoch : 97 [390/391]| loss: 0.141 | acc: 95.372\n",
      "test epoch : 97 [78/79]| loss: 0.394 | acc: 89.320\n",
      "best test accuracy is  89.68\n",
      "train epoch : 98 [390/391]| loss: 0.143 | acc: 95.254\n",
      "test epoch : 98 [78/79]| loss: 0.442 | acc: 87.410\n",
      "best test accuracy is  89.68\n",
      "train epoch : 99 [390/391]| loss: 0.139 | acc: 95.470\n",
      "test epoch : 99 [78/79]| loss: 0.515 | acc: 86.060\n",
      "best test accuracy is  89.68\n",
      "train epoch : 100 [390/391]| loss: 0.140 | acc: 95.360\n",
      "test epoch : 100 [78/79]| loss: 0.491 | acc: 86.420\n",
      "best test accuracy is  89.68\n",
      "train epoch : 101 [390/391]| loss: 0.141 | acc: 95.404\n",
      "test epoch : 101 [78/79]| loss: 0.394 | acc: 88.770\n",
      "best test accuracy is  89.68\n",
      "train epoch : 102 [390/391]| loss: 0.146 | acc: 95.188\n",
      "test epoch : 102 [78/79]| loss: 0.413 | acc: 87.950\n",
      "best test accuracy is  89.68\n",
      "train epoch : 103 [390/391]| loss: 0.139 | acc: 95.462\n",
      "test epoch : 103 [78/79]| loss: 0.381 | acc: 89.070\n",
      "best test accuracy is  89.68\n",
      "train epoch : 104 [390/391]| loss: 0.137 | acc: 95.614\n",
      "test epoch : 104 [78/79]| loss: 0.412 | acc: 88.350\n",
      "best test accuracy is  89.68\n",
      "train epoch : 105 [390/391]| loss: 0.139 | acc: 95.476\n",
      "test epoch : 105 [78/79]| loss: 0.438 | acc: 87.750\n",
      "best test accuracy is  89.68\n",
      "train epoch : 106 [390/391]| loss: 0.134 | acc: 95.696\n",
      "test epoch : 106 [78/79]| loss: 0.429 | acc: 88.530\n",
      "best test accuracy is  89.68\n",
      "train epoch : 107 [390/391]| loss: 0.138 | acc: 95.468\n",
      "test epoch : 107 [78/79]| loss: 0.492 | acc: 86.860\n",
      "best test accuracy is  89.68\n",
      "train epoch : 108 [390/391]| loss: 0.139 | acc: 95.452\n",
      "test epoch : 108 [78/79]| loss: 0.481 | acc: 87.540\n",
      "best test accuracy is  89.68\n",
      "train epoch : 109 [390/391]| loss: 0.134 | acc: 95.674\n",
      "test epoch : 109 [78/79]| loss: 0.477 | acc: 86.710\n",
      "best test accuracy is  89.68\n",
      "train epoch : 110 [390/391]| loss: 0.136 | acc: 95.642\n",
      "test epoch : 110 [78/79]| loss: 0.429 | acc: 87.480\n",
      "best test accuracy is  89.68\n",
      "train epoch : 111 [390/391]| loss: 0.129 | acc: 95.740\n",
      "test epoch : 111 [78/79]| loss: 0.456 | acc: 88.230\n",
      "best test accuracy is  89.68\n",
      "train epoch : 112 [390/391]| loss: 0.137 | acc: 95.598\n",
      "test epoch : 112 [78/79]| loss: 0.454 | acc: 88.510\n",
      "best test accuracy is  89.68\n",
      "train epoch : 113 [390/391]| loss: 0.133 | acc: 95.626\n",
      "test epoch : 113 [78/79]| loss: 0.399 | acc: 88.680\n",
      "best test accuracy is  89.68\n",
      "train epoch : 114 [390/391]| loss: 0.140 | acc: 95.530\n",
      "test epoch : 114 [78/79]| loss: 0.479 | acc: 87.250\n",
      "best test accuracy is  89.68\n",
      "train epoch : 115 [390/391]| loss: 0.132 | acc: 95.702\n",
      "test epoch : 115 [78/79]| loss: 0.530 | acc: 86.250\n",
      "best test accuracy is  89.68\n",
      "train epoch : 116 [390/391]| loss: 0.137 | acc: 95.532\n",
      "test epoch : 116 [78/79]| loss: 0.478 | acc: 87.480\n",
      "best test accuracy is  89.68\n",
      "train epoch : 117 [390/391]| loss: 0.135 | acc: 95.638\n",
      "test epoch : 117 [78/79]| loss: 0.510 | acc: 86.590\n",
      "best test accuracy is  89.68\n",
      "train epoch : 118 [390/391]| loss: 0.133 | acc: 95.574\n",
      "test epoch : 118 [78/79]| loss: 0.526 | acc: 85.760\n",
      "best test accuracy is  89.68\n",
      "train epoch : 119 [390/391]| loss: 0.126 | acc: 95.890\n",
      "test epoch : 119 [78/79]| loss: 0.457 | acc: 87.110\n",
      "best test accuracy is  89.68\n",
      "train epoch : 120 [390/391]| loss: 0.128 | acc: 95.896\n",
      "test epoch : 120 [78/79]| loss: 0.386 | acc: 89.400\n",
      "best test accuracy is  89.68\n",
      "train epoch : 121 [390/391]| loss: 0.135 | acc: 95.556\n",
      "test epoch : 121 [78/79]| loss: 0.435 | acc: 87.960\n",
      "best test accuracy is  89.68\n",
      "train epoch : 122 [390/391]| loss: 0.137 | acc: 95.468\n",
      "test epoch : 122 [78/79]| loss: 0.435 | acc: 87.900\n",
      "best test accuracy is  89.68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 123 [390/391]| loss: 0.134 | acc: 95.634\n",
      "test epoch : 123 [78/79]| loss: 0.435 | acc: 87.850\n",
      "best test accuracy is  89.68\n",
      "train epoch : 124 [390/391]| loss: 0.130 | acc: 95.742\n",
      "test epoch : 124 [78/79]| loss: 0.414 | acc: 88.600\n",
      "best test accuracy is  89.68\n",
      "train epoch : 125 [390/391]| loss: 0.130 | acc: 95.718\n",
      "test epoch : 125 [78/79]| loss: 0.404 | acc: 88.460\n",
      "best test accuracy is  89.68\n",
      "train epoch : 126 [390/391]| loss: 0.133 | acc: 95.716\n",
      "test epoch : 126 [78/79]| loss: 0.368 | acc: 89.440\n",
      "best test accuracy is  89.68\n",
      "train epoch : 127 [390/391]| loss: 0.128 | acc: 95.846\n",
      "test epoch : 127 [78/79]| loss: 0.400 | acc: 88.710\n",
      "best test accuracy is  89.68\n",
      "train epoch : 128 [390/391]| loss: 0.126 | acc: 95.952\n",
      "test epoch : 128 [78/79]| loss: 0.407 | acc: 88.710\n",
      "best test accuracy is  89.68\n",
      "train epoch : 129 [390/391]| loss: 0.126 | acc: 95.906\n",
      "test epoch : 129 [78/79]| loss: 0.424 | acc: 88.360\n",
      "best test accuracy is  89.68\n",
      "train epoch : 130 [390/391]| loss: 0.130 | acc: 95.828\n",
      "test epoch : 130 [78/79]| loss: 0.419 | acc: 88.520\n",
      "best test accuracy is  89.68\n",
      "train epoch : 131 [390/391]| loss: 0.133 | acc: 95.708\n",
      "test epoch : 131 [78/79]| loss: 0.500 | acc: 87.180\n",
      "best test accuracy is  89.68\n",
      "train epoch : 132 [390/391]| loss: 0.130 | acc: 95.812\n",
      "test epoch : 132 [78/79]| loss: 0.417 | acc: 89.000\n",
      "best test accuracy is  89.68\n",
      "train epoch : 133 [390/391]| loss: 0.128 | acc: 95.826\n",
      "test epoch : 133 [78/79]| loss: 0.473 | acc: 87.090\n",
      "best test accuracy is  89.68\n",
      "train epoch : 134 [390/391]| loss: 0.128 | acc: 95.794\n",
      "test epoch : 134 [78/79]| loss: 0.389 | acc: 89.280\n",
      "best test accuracy is  89.68\n",
      "train epoch : 135 [390/391]| loss: 0.132 | acc: 95.740\n",
      "test epoch : 135 [78/79]| loss: 0.519 | acc: 86.420\n",
      "best test accuracy is  89.68\n",
      "train epoch : 136 [390/391]| loss: 0.128 | acc: 95.938\n",
      "test epoch : 136 [78/79]| loss: 0.372 | acc: 89.520\n",
      "best test accuracy is  89.68\n",
      "train epoch : 137 [390/391]| loss: 0.126 | acc: 95.984\n",
      "test epoch : 137 [78/79]| loss: 0.407 | acc: 89.350\n",
      "best test accuracy is  89.68\n",
      "train epoch : 138 [390/391]| loss: 0.133 | acc: 95.708\n",
      "test epoch : 138 [78/79]| loss: 0.433 | acc: 87.490\n",
      "best test accuracy is  89.68\n",
      "train epoch : 139 [390/391]| loss: 0.133 | acc: 95.614\n",
      "test epoch : 139 [78/79]| loss: 0.492 | acc: 86.530\n",
      "best test accuracy is  89.68\n",
      "train epoch : 140 [390/391]| loss: 0.129 | acc: 95.778\n",
      "test epoch : 140 [78/79]| loss: 0.399 | acc: 89.250\n",
      "best test accuracy is  89.68\n",
      "train epoch : 141 [390/391]| loss: 0.129 | acc: 95.790\n",
      "test epoch : 141 [78/79]| loss: 0.456 | acc: 88.380\n",
      "best test accuracy is  89.68\n",
      "train epoch : 142 [390/391]| loss: 0.126 | acc: 95.880\n",
      "test epoch : 142 [78/79]| loss: 0.374 | acc: 89.910\n",
      "best test accuracy is  89.91\n",
      "train epoch : 143 [390/391]| loss: 0.124 | acc: 95.908\n",
      "test epoch : 143 [78/79]| loss: 0.410 | acc: 88.820\n",
      "best test accuracy is  89.91\n",
      "train epoch : 144 [390/391]| loss: 0.123 | acc: 95.946\n",
      "test epoch : 144 [78/79]| loss: 0.424 | acc: 88.780\n",
      "best test accuracy is  89.91\n",
      "train epoch : 145 [390/391]| loss: 0.123 | acc: 96.044\n",
      "test epoch : 145 [78/79]| loss: 0.407 | acc: 88.780\n",
      "best test accuracy is  89.91\n",
      "train epoch : 146 [390/391]| loss: 0.126 | acc: 95.862\n",
      "test epoch : 146 [78/79]| loss: 0.399 | acc: 89.060\n",
      "best test accuracy is  89.91\n",
      "train epoch : 147 [390/391]| loss: 0.126 | acc: 95.896\n",
      "test epoch : 147 [78/79]| loss: 0.445 | acc: 87.530\n",
      "best test accuracy is  89.91\n",
      "train epoch : 148 [390/391]| loss: 0.124 | acc: 95.984\n",
      "test epoch : 148 [78/79]| loss: 0.444 | acc: 88.010\n",
      "best test accuracy is  89.91\n",
      "train epoch : 149 [390/391]| loss: 0.131 | acc: 95.786\n",
      "test epoch : 149 [78/79]| loss: 0.413 | acc: 88.460\n",
      "best test accuracy is  89.91\n",
      "train epoch : 150 [390/391]| loss: 0.126 | acc: 95.842\n",
      "test epoch : 150 [78/79]| loss: 0.478 | acc: 88.240\n",
      "best test accuracy is  89.91\n",
      "train epoch : 151 [390/391]| loss: 0.120 | acc: 95.982\n",
      "test epoch : 151 [78/79]| loss: 0.408 | acc: 88.360\n",
      "best test accuracy is  89.91\n",
      "train epoch : 152 [390/391]| loss: 0.125 | acc: 95.950\n",
      "test epoch : 152 [78/79]| loss: 0.397 | acc: 88.940\n",
      "best test accuracy is  89.91\n",
      "train epoch : 153 [390/391]| loss: 0.125 | acc: 95.944\n",
      "test epoch : 153 [78/79]| loss: 0.453 | acc: 87.560\n",
      "best test accuracy is  89.91\n",
      "train epoch : 154 [390/391]| loss: 0.122 | acc: 96.034\n",
      "test epoch : 154 [78/79]| loss: 0.490 | acc: 87.640\n",
      "best test accuracy is  89.91\n",
      "train epoch : 155 [390/391]| loss: 0.125 | acc: 95.974\n",
      "test epoch : 155 [78/79]| loss: 0.449 | acc: 88.220\n",
      "best test accuracy is  89.91\n",
      "train epoch : 156 [390/391]| loss: 0.127 | acc: 95.778\n",
      "test epoch : 156 [78/79]| loss: 0.443 | acc: 88.790\n",
      "best test accuracy is  89.91\n",
      "train epoch : 157 [390/391]| loss: 0.131 | acc: 95.724\n",
      "test epoch : 157 [78/79]| loss: 0.425 | acc: 88.300\n",
      "best test accuracy is  89.91\n",
      "train epoch : 158 [390/391]| loss: 0.125 | acc: 95.948\n",
      "test epoch : 158 [78/79]| loss: 0.443 | acc: 86.860\n",
      "best test accuracy is  89.91\n",
      "train epoch : 159 [390/391]| loss: 0.123 | acc: 95.966\n",
      "test epoch : 159 [78/79]| loss: 0.372 | acc: 89.770\n",
      "best test accuracy is  89.91\n",
      "train epoch : 160 [390/391]| loss: 0.122 | acc: 96.038\n",
      "test epoch : 160 [78/79]| loss: 0.502 | acc: 86.910\n",
      "best test accuracy is  89.91\n",
      "train epoch : 161 [390/391]| loss: 0.122 | acc: 96.016\n",
      "test epoch : 161 [78/79]| loss: 0.428 | acc: 87.820\n",
      "best test accuracy is  89.91\n",
      "train epoch : 162 [390/391]| loss: 0.114 | acc: 96.264\n",
      "test epoch : 162 [78/79]| loss: 0.467 | acc: 87.330\n",
      "best test accuracy is  89.91\n",
      "train epoch : 163 [390/391]| loss: 0.123 | acc: 95.938\n",
      "test epoch : 163 [78/79]| loss: 0.389 | acc: 88.920\n",
      "best test accuracy is  89.91\n",
      "train epoch : 164 [390/391]| loss: 0.129 | acc: 95.788\n",
      "test epoch : 164 [78/79]| loss: 0.397 | acc: 88.880\n",
      "best test accuracy is  89.91\n"
     ]
    }
   ],
   "source": [
    "# Training and testing codes referred \n",
    "# from https://github.com/dnddnjs/pytorch-cifar10/blob/master/resnet/train.py\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "net = VGG19(cfg=cfg)\n",
    "net = net.to(device)\n",
    "num_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "print('The number of parameters of model is', num_params)\n",
    "# print(net)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, \n",
    "                      momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "def train(epoch, global_steps):\n",
    "    net.train()\n",
    "\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        global_steps += 1\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    acc = 100 * correct / total\n",
    "    print('train epoch : {} [{}/{}]| loss: {:.3f} | acc: {:.3f}'.format(\n",
    "           epoch, batch_idx, len(train_loader), train_loss/(batch_idx+1), acc))\n",
    "\n",
    "    return global_steps\n",
    "\n",
    "\n",
    "def test(epoch, best_acc, global_steps):\n",
    "    net.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    acc = 100 * correct / total\n",
    "    print('test epoch : {} [{}/{}]| loss: {:.3f} | acc: {:.3f}'.format(\n",
    "           epoch, batch_idx, len(test_loader), test_loss/(batch_idx+1), acc))\n",
    "\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "\n",
    "    return best_acc\n",
    "\n",
    "best_acc = 0\n",
    "epoch = 0\n",
    "global_steps = 0\n",
    "\n",
    "while True:\n",
    "    epoch += 1\n",
    "    global_steps = train(epoch, global_steps)\n",
    "    best_acc = test(epoch, best_acc, global_steps)\n",
    "    print('best test accuracy is ', best_acc)\n",
    "\n",
    "    if global_steps >= 64000:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.88\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "print(100 * correct / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transforms_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "transforms_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "dataset_train = torchvision.datasets.CIFAR10(root='./data', train=True, \n",
    "                        download=True, transform=transforms_train)\n",
    "dataset_test = torchvision.datasets.CIFAR10(root='./data', train=False, \n",
    "                       download=True, transform=transforms_test)\n",
    "train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=128, \n",
    "                          shuffle=True, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(dataset_test, batch_size=128, \n",
    "                         shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_32 = [\"16\", \"16\", \"16\", \"16\", \"16\", \"32P\", \"32\", \"32\", \"32\", \"32\", \"64P\", \"64\", \"64\", \"64\", \"64\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BuildingBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, downsample=False):\n",
    "        super(BuildingBlock, self).__init__()\n",
    "        in_stride = 1\n",
    "        if downsample:\n",
    "            in_stride = 2\n",
    "        self.layers = nn.Sequential(*[\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=in_stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        ])\n",
    "        self.downsample = downsample\n",
    "        self.pool = nn.MaxPool2d(1, stride=in_stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        if self.downsample:\n",
    "            x = F.pad(x, (0, 0, 0, 0, 0, out.size(1) - x.size(1)))\n",
    "            x = self.pool(x)\n",
    "        out = out + x\n",
    "        # print(out.size(), x.size())\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block_cfg):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.first_layer = nn.Sequential(*[\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True)\n",
    "        ])\n",
    "        self.blocks = self._make_blocks(block_cfg)\n",
    "        self.pool_layer = nn.AvgPool2d(8, stride=1)\n",
    "        self.fc = nn.Linear(64, 10)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _make_blocks(self, block_cfg,):\n",
    "        in_channels = 16\n",
    "        blocks = []\n",
    "        for item in block_cfg:\n",
    "            if item[-1] == \"P\":\n",
    "                downsample = True\n",
    "                out_channels = int(item[:-1])\n",
    "            else:\n",
    "                downsample = False\n",
    "                out_channels = int(item)\n",
    "            block = BuildingBlock(in_channels, out_channels, downsample)\n",
    "            blocks.append(block)\n",
    "            in_channels = out_channels\n",
    "        blocks = nn.ModuleList(blocks)\n",
    "        return nn.Sequential(*blocks)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.first_layer(x)\n",
    "        out = self.blocks(out)\n",
    "        out = self.pool_layer(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of parameters of model is 464154\n",
      "train epoch : 1 [390/391]| loss: 1.757 | acc: 33.984\n",
      "test epoch : 1 [78/79]| loss: 1.763 | acc: 37.110\n",
      "best test accuracy is  37.11\n",
      "train epoch : 2 [390/391]| loss: 1.235 | acc: 54.910\n",
      "test epoch : 2 [78/79]| loss: 1.185 | acc: 59.390\n",
      "best test accuracy is  59.39\n",
      "train epoch : 3 [390/391]| loss: 0.982 | acc: 65.096\n",
      "test epoch : 3 [78/79]| loss: 1.098 | acc: 61.450\n",
      "best test accuracy is  61.45\n",
      "train epoch : 4 [390/391]| loss: 0.800 | acc: 71.862\n",
      "test epoch : 4 [78/79]| loss: 0.807 | acc: 72.150\n",
      "best test accuracy is  72.15\n",
      "train epoch : 5 [390/391]| loss: 0.685 | acc: 75.942\n",
      "test epoch : 5 [78/79]| loss: 0.863 | acc: 71.110\n",
      "best test accuracy is  72.15\n",
      "train epoch : 6 [390/391]| loss: 0.611 | acc: 78.698\n",
      "test epoch : 6 [78/79]| loss: 0.812 | acc: 74.400\n",
      "best test accuracy is  74.4\n",
      "train epoch : 7 [390/391]| loss: 0.560 | acc: 80.524\n",
      "test epoch : 7 [78/79]| loss: 0.628 | acc: 78.970\n",
      "best test accuracy is  78.97\n",
      "train epoch : 8 [390/391]| loss: 0.516 | acc: 82.122\n",
      "test epoch : 8 [78/79]| loss: 0.863 | acc: 73.240\n",
      "best test accuracy is  78.97\n",
      "train epoch : 9 [390/391]| loss: 0.491 | acc: 83.048\n",
      "test epoch : 9 [78/79]| loss: 0.645 | acc: 79.050\n",
      "best test accuracy is  79.05\n",
      "train epoch : 10 [390/391]| loss: 0.463 | acc: 84.006\n",
      "test epoch : 10 [78/79]| loss: 0.631 | acc: 79.940\n",
      "best test accuracy is  79.94\n",
      "train epoch : 11 [390/391]| loss: 0.438 | acc: 84.776\n",
      "test epoch : 11 [78/79]| loss: 0.556 | acc: 80.800\n",
      "best test accuracy is  80.8\n",
      "train epoch : 12 [390/391]| loss: 0.416 | acc: 85.540\n",
      "test epoch : 12 [78/79]| loss: 0.473 | acc: 83.790\n",
      "best test accuracy is  83.79\n",
      "train epoch : 13 [390/391]| loss: 0.404 | acc: 86.038\n",
      "test epoch : 13 [78/79]| loss: 0.536 | acc: 82.630\n",
      "best test accuracy is  83.79\n",
      "train epoch : 14 [390/391]| loss: 0.389 | acc: 86.548\n",
      "test epoch : 14 [78/79]| loss: 0.685 | acc: 78.800\n",
      "best test accuracy is  83.79\n",
      "train epoch : 15 [390/391]| loss: 0.376 | acc: 87.146\n",
      "test epoch : 15 [78/79]| loss: 0.554 | acc: 81.440\n",
      "best test accuracy is  83.79\n",
      "train epoch : 16 [390/391]| loss: 0.366 | acc: 87.306\n",
      "test epoch : 16 [78/79]| loss: 0.488 | acc: 84.100\n",
      "best test accuracy is  84.1\n",
      "train epoch : 17 [390/391]| loss: 0.352 | acc: 87.780\n",
      "test epoch : 17 [78/79]| loss: 0.599 | acc: 81.520\n",
      "best test accuracy is  84.1\n",
      "train epoch : 18 [390/391]| loss: 0.343 | acc: 88.068\n",
      "test epoch : 18 [78/79]| loss: 0.542 | acc: 83.640\n",
      "best test accuracy is  84.1\n",
      "train epoch : 19 [390/391]| loss: 0.334 | acc: 88.436\n",
      "test epoch : 19 [78/79]| loss: 0.455 | acc: 84.850\n",
      "best test accuracy is  84.85\n",
      "train epoch : 20 [390/391]| loss: 0.324 | acc: 88.848\n",
      "test epoch : 20 [78/79]| loss: 0.474 | acc: 84.110\n",
      "best test accuracy is  84.85\n",
      "train epoch : 21 [390/391]| loss: 0.322 | acc: 88.684\n",
      "test epoch : 21 [78/79]| loss: 0.553 | acc: 81.860\n",
      "best test accuracy is  84.85\n",
      "train epoch : 22 [390/391]| loss: 0.313 | acc: 89.040\n",
      "test epoch : 22 [78/79]| loss: 0.478 | acc: 85.030\n",
      "best test accuracy is  85.03\n",
      "train epoch : 23 [390/391]| loss: 0.305 | acc: 89.542\n",
      "test epoch : 23 [78/79]| loss: 0.515 | acc: 83.480\n",
      "best test accuracy is  85.03\n",
      "train epoch : 24 [390/391]| loss: 0.300 | acc: 89.606\n",
      "test epoch : 24 [78/79]| loss: 0.505 | acc: 84.470\n",
      "best test accuracy is  85.03\n",
      "train epoch : 25 [390/391]| loss: 0.296 | acc: 89.618\n",
      "test epoch : 25 [78/79]| loss: 0.481 | acc: 84.540\n",
      "best test accuracy is  85.03\n",
      "train epoch : 26 [390/391]| loss: 0.289 | acc: 89.882\n",
      "test epoch : 26 [78/79]| loss: 0.460 | acc: 85.120\n",
      "best test accuracy is  85.12\n",
      "train epoch : 27 [390/391]| loss: 0.282 | acc: 90.208\n",
      "test epoch : 27 [78/79]| loss: 0.471 | acc: 85.300\n",
      "best test accuracy is  85.3\n",
      "train epoch : 28 [390/391]| loss: 0.280 | acc: 90.260\n",
      "test epoch : 28 [78/79]| loss: 0.523 | acc: 84.200\n",
      "best test accuracy is  85.3\n",
      "train epoch : 29 [390/391]| loss: 0.277 | acc: 90.384\n",
      "test epoch : 29 [78/79]| loss: 0.408 | acc: 87.340\n",
      "best test accuracy is  87.34\n",
      "train epoch : 30 [390/391]| loss: 0.278 | acc: 90.404\n",
      "test epoch : 30 [78/79]| loss: 0.482 | acc: 84.130\n",
      "best test accuracy is  87.34\n",
      "train epoch : 31 [390/391]| loss: 0.265 | acc: 90.622\n",
      "test epoch : 31 [78/79]| loss: 0.434 | acc: 86.270\n",
      "best test accuracy is  87.34\n",
      "train epoch : 32 [390/391]| loss: 0.262 | acc: 90.870\n",
      "test epoch : 32 [78/79]| loss: 0.460 | acc: 85.420\n",
      "best test accuracy is  87.34\n",
      "train epoch : 33 [390/391]| loss: 0.261 | acc: 90.782\n",
      "test epoch : 33 [78/79]| loss: 0.523 | acc: 83.620\n",
      "best test accuracy is  87.34\n",
      "train epoch : 34 [390/391]| loss: 0.260 | acc: 90.868\n",
      "test epoch : 34 [78/79]| loss: 0.425 | acc: 86.500\n",
      "best test accuracy is  87.34\n",
      "train epoch : 35 [390/391]| loss: 0.254 | acc: 91.106\n",
      "test epoch : 35 [78/79]| loss: 0.381 | acc: 87.830\n",
      "best test accuracy is  87.83\n",
      "train epoch : 36 [390/391]| loss: 0.254 | acc: 91.326\n",
      "test epoch : 36 [78/79]| loss: 0.393 | acc: 87.220\n",
      "best test accuracy is  87.83\n",
      "train epoch : 37 [390/391]| loss: 0.246 | acc: 91.472\n",
      "test epoch : 37 [78/79]| loss: 0.478 | acc: 85.070\n",
      "best test accuracy is  87.83\n",
      "train epoch : 38 [390/391]| loss: 0.236 | acc: 91.772\n",
      "test epoch : 38 [78/79]| loss: 0.456 | acc: 85.940\n",
      "best test accuracy is  87.83\n",
      "train epoch : 39 [390/391]| loss: 0.243 | acc: 91.520\n",
      "test epoch : 39 [78/79]| loss: 0.732 | acc: 81.100\n",
      "best test accuracy is  87.83\n",
      "train epoch : 40 [390/391]| loss: 0.238 | acc: 91.668\n",
      "test epoch : 40 [78/79]| loss: 0.513 | acc: 84.150\n",
      "best test accuracy is  87.83\n",
      "train epoch : 41 [390/391]| loss: 0.238 | acc: 91.684\n",
      "test epoch : 41 [78/79]| loss: 0.410 | acc: 87.310\n",
      "best test accuracy is  87.83\n",
      "train epoch : 42 [390/391]| loss: 0.237 | acc: 91.666\n",
      "test epoch : 42 [78/79]| loss: 0.459 | acc: 85.810\n",
      "best test accuracy is  87.83\n",
      "train epoch : 43 [390/391]| loss: 0.230 | acc: 92.028\n",
      "test epoch : 43 [78/79]| loss: 0.450 | acc: 86.220\n",
      "best test accuracy is  87.83\n",
      "train epoch : 44 [390/391]| loss: 0.232 | acc: 91.882\n",
      "test epoch : 44 [78/79]| loss: 0.500 | acc: 84.320\n",
      "best test accuracy is  87.83\n",
      "train epoch : 45 [390/391]| loss: 0.230 | acc: 92.010\n",
      "test epoch : 45 [78/79]| loss: 0.394 | acc: 87.380\n",
      "best test accuracy is  87.83\n",
      "train epoch : 46 [390/391]| loss: 0.231 | acc: 92.014\n",
      "test epoch : 46 [78/79]| loss: 0.441 | acc: 86.640\n",
      "best test accuracy is  87.83\n",
      "train epoch : 47 [390/391]| loss: 0.226 | acc: 92.126\n",
      "test epoch : 47 [78/79]| loss: 0.469 | acc: 85.640\n",
      "best test accuracy is  87.83\n",
      "train epoch : 48 [390/391]| loss: 0.226 | acc: 92.054\n",
      "test epoch : 48 [78/79]| loss: 0.484 | acc: 85.090\n",
      "best test accuracy is  87.83\n",
      "train epoch : 49 [390/391]| loss: 0.221 | acc: 92.246\n",
      "test epoch : 49 [78/79]| loss: 0.420 | acc: 87.100\n",
      "best test accuracy is  87.83\n",
      "train epoch : 50 [390/391]| loss: 0.227 | acc: 91.940\n",
      "test epoch : 50 [78/79]| loss: 0.622 | acc: 83.050\n",
      "best test accuracy is  87.83\n",
      "train epoch : 51 [390/391]| loss: 0.218 | acc: 92.292\n",
      "test epoch : 51 [78/79]| loss: 0.412 | acc: 87.290\n",
      "best test accuracy is  87.83\n",
      "train epoch : 52 [390/391]| loss: 0.213 | acc: 92.666\n",
      "test epoch : 52 [78/79]| loss: 0.427 | acc: 86.910\n",
      "best test accuracy is  87.83\n",
      "train epoch : 53 [390/391]| loss: 0.219 | acc: 92.226\n",
      "test epoch : 53 [78/79]| loss: 0.438 | acc: 86.150\n",
      "best test accuracy is  87.83\n",
      "train epoch : 54 [390/391]| loss: 0.208 | acc: 92.790\n",
      "test epoch : 54 [78/79]| loss: 0.427 | acc: 87.370\n",
      "best test accuracy is  87.83\n",
      "train epoch : 55 [390/391]| loss: 0.212 | acc: 92.588\n",
      "test epoch : 55 [78/79]| loss: 0.484 | acc: 86.230\n",
      "best test accuracy is  87.83\n",
      "train epoch : 56 [390/391]| loss: 0.210 | acc: 92.718\n",
      "test epoch : 56 [78/79]| loss: 0.501 | acc: 85.780\n",
      "best test accuracy is  87.83\n",
      "train epoch : 57 [390/391]| loss: 0.209 | acc: 92.752\n",
      "test epoch : 57 [78/79]| loss: 0.457 | acc: 85.710\n",
      "best test accuracy is  87.83\n",
      "train epoch : 58 [390/391]| loss: 0.208 | acc: 92.710\n",
      "test epoch : 58 [78/79]| loss: 0.455 | acc: 86.610\n",
      "best test accuracy is  87.83\n",
      "train epoch : 59 [390/391]| loss: 0.211 | acc: 92.536\n",
      "test epoch : 59 [78/79]| loss: 0.469 | acc: 85.100\n",
      "best test accuracy is  87.83\n",
      "train epoch : 60 [390/391]| loss: 0.207 | acc: 92.742\n",
      "test epoch : 60 [78/79]| loss: 0.477 | acc: 84.980\n",
      "best test accuracy is  87.83\n",
      "train epoch : 61 [390/391]| loss: 0.203 | acc: 92.994\n",
      "test epoch : 61 [78/79]| loss: 0.400 | acc: 87.900\n",
      "best test accuracy is  87.9\n",
      "train epoch : 62 [390/391]| loss: 0.213 | acc: 92.462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 62 [78/79]| loss: 0.468 | acc: 85.680\n",
      "best test accuracy is  87.9\n",
      "train epoch : 63 [390/391]| loss: 0.202 | acc: 92.818\n",
      "test epoch : 63 [78/79]| loss: 0.397 | acc: 87.630\n",
      "best test accuracy is  87.9\n",
      "train epoch : 64 [390/391]| loss: 0.203 | acc: 92.846\n",
      "test epoch : 64 [78/79]| loss: 0.407 | acc: 87.630\n",
      "best test accuracy is  87.9\n",
      "train epoch : 65 [390/391]| loss: 0.202 | acc: 92.914\n",
      "test epoch : 65 [78/79]| loss: 0.373 | acc: 88.610\n",
      "best test accuracy is  88.61\n",
      "train epoch : 66 [390/391]| loss: 0.200 | acc: 93.042\n",
      "test epoch : 66 [78/79]| loss: 0.455 | acc: 86.350\n",
      "best test accuracy is  88.61\n",
      "train epoch : 67 [390/391]| loss: 0.202 | acc: 92.858\n",
      "test epoch : 67 [78/79]| loss: 0.406 | acc: 86.660\n",
      "best test accuracy is  88.61\n",
      "train epoch : 68 [390/391]| loss: 0.203 | acc: 92.856\n",
      "test epoch : 68 [78/79]| loss: 0.407 | acc: 87.420\n",
      "best test accuracy is  88.61\n",
      "train epoch : 69 [390/391]| loss: 0.202 | acc: 92.842\n",
      "test epoch : 69 [78/79]| loss: 0.406 | acc: 87.460\n",
      "best test accuracy is  88.61\n",
      "train epoch : 70 [390/391]| loss: 0.199 | acc: 92.950\n",
      "test epoch : 70 [78/79]| loss: 0.400 | acc: 87.890\n",
      "best test accuracy is  88.61\n",
      "train epoch : 71 [390/391]| loss: 0.192 | acc: 93.312\n",
      "test epoch : 71 [78/79]| loss: 0.475 | acc: 86.290\n",
      "best test accuracy is  88.61\n",
      "train epoch : 72 [390/391]| loss: 0.197 | acc: 93.066\n",
      "test epoch : 72 [78/79]| loss: 0.506 | acc: 85.300\n",
      "best test accuracy is  88.61\n",
      "train epoch : 73 [390/391]| loss: 0.196 | acc: 93.094\n",
      "test epoch : 73 [78/79]| loss: 0.527 | acc: 85.500\n",
      "best test accuracy is  88.61\n",
      "train epoch : 74 [390/391]| loss: 0.196 | acc: 93.034\n",
      "test epoch : 74 [78/79]| loss: 0.468 | acc: 86.410\n",
      "best test accuracy is  88.61\n",
      "train epoch : 75 [390/391]| loss: 0.195 | acc: 93.096\n",
      "test epoch : 75 [78/79]| loss: 0.456 | acc: 86.760\n",
      "best test accuracy is  88.61\n",
      "train epoch : 76 [390/391]| loss: 0.192 | acc: 93.176\n",
      "test epoch : 76 [78/79]| loss: 0.385 | acc: 88.400\n",
      "best test accuracy is  88.61\n",
      "train epoch : 77 [390/391]| loss: 0.192 | acc: 93.284\n",
      "test epoch : 77 [78/79]| loss: 0.344 | acc: 89.270\n",
      "best test accuracy is  89.27\n",
      "train epoch : 78 [390/391]| loss: 0.189 | acc: 93.386\n",
      "test epoch : 78 [78/79]| loss: 0.366 | acc: 88.910\n",
      "best test accuracy is  89.27\n",
      "train epoch : 79 [390/391]| loss: 0.185 | acc: 93.598\n",
      "test epoch : 79 [78/79]| loss: 0.439 | acc: 87.040\n",
      "best test accuracy is  89.27\n",
      "train epoch : 80 [390/391]| loss: 0.194 | acc: 93.348\n",
      "test epoch : 80 [78/79]| loss: 0.427 | acc: 86.870\n",
      "best test accuracy is  89.27\n",
      "train epoch : 81 [390/391]| loss: 0.185 | acc: 93.540\n",
      "test epoch : 81 [78/79]| loss: 0.464 | acc: 86.510\n",
      "best test accuracy is  89.27\n",
      "train epoch : 82 [390/391]| loss: 0.185 | acc: 93.514\n",
      "test epoch : 82 [78/79]| loss: 0.301 | acc: 90.670\n",
      "best test accuracy is  90.67\n",
      "train epoch : 83 [390/391]| loss: 0.099 | acc: 96.692\n",
      "test epoch : 83 [78/79]| loss: 0.270 | acc: 91.670\n",
      "best test accuracy is  91.67\n",
      "train epoch : 84 [390/391]| loss: 0.078 | acc: 97.428\n",
      "test epoch : 84 [78/79]| loss: 0.267 | acc: 91.910\n",
      "best test accuracy is  91.91\n",
      "train epoch : 85 [390/391]| loss: 0.070 | acc: 97.752\n",
      "test epoch : 85 [78/79]| loss: 0.268 | acc: 92.220\n",
      "best test accuracy is  92.22\n",
      "train epoch : 86 [390/391]| loss: 0.062 | acc: 97.890\n",
      "test epoch : 86 [78/79]| loss: 0.272 | acc: 92.130\n",
      "best test accuracy is  92.22\n",
      "train epoch : 87 [390/391]| loss: 0.057 | acc: 98.084\n",
      "test epoch : 87 [78/79]| loss: 0.277 | acc: 92.140\n",
      "best test accuracy is  92.22\n",
      "train epoch : 88 [390/391]| loss: 0.052 | acc: 98.352\n",
      "test epoch : 88 [78/79]| loss: 0.277 | acc: 92.060\n",
      "best test accuracy is  92.22\n",
      "train epoch : 89 [390/391]| loss: 0.050 | acc: 98.404\n",
      "test epoch : 89 [78/79]| loss: 0.274 | acc: 92.290\n",
      "best test accuracy is  92.29\n",
      "train epoch : 90 [390/391]| loss: 0.047 | acc: 98.456\n",
      "test epoch : 90 [78/79]| loss: 0.280 | acc: 92.370\n",
      "best test accuracy is  92.37\n",
      "train epoch : 91 [390/391]| loss: 0.045 | acc: 98.532\n",
      "test epoch : 91 [78/79]| loss: 0.284 | acc: 92.340\n",
      "best test accuracy is  92.37\n",
      "train epoch : 92 [390/391]| loss: 0.040 | acc: 98.760\n",
      "test epoch : 92 [78/79]| loss: 0.290 | acc: 92.420\n",
      "best test accuracy is  92.42\n",
      "train epoch : 93 [390/391]| loss: 0.040 | acc: 98.724\n",
      "test epoch : 93 [78/79]| loss: 0.293 | acc: 92.180\n",
      "best test accuracy is  92.42\n",
      "train epoch : 94 [390/391]| loss: 0.038 | acc: 98.800\n",
      "test epoch : 94 [78/79]| loss: 0.292 | acc: 92.370\n",
      "best test accuracy is  92.42\n",
      "train epoch : 95 [390/391]| loss: 0.035 | acc: 98.938\n",
      "test epoch : 95 [78/79]| loss: 0.297 | acc: 92.260\n",
      "best test accuracy is  92.42\n",
      "train epoch : 96 [390/391]| loss: 0.034 | acc: 98.942\n",
      "test epoch : 96 [78/79]| loss: 0.297 | acc: 92.460\n",
      "best test accuracy is  92.46\n",
      "train epoch : 97 [390/391]| loss: 0.032 | acc: 98.980\n",
      "test epoch : 97 [78/79]| loss: 0.305 | acc: 92.210\n",
      "best test accuracy is  92.46\n",
      "train epoch : 98 [390/391]| loss: 0.032 | acc: 98.984\n",
      "test epoch : 98 [78/79]| loss: 0.306 | acc: 92.410\n",
      "best test accuracy is  92.46\n",
      "train epoch : 99 [390/391]| loss: 0.030 | acc: 99.106\n",
      "test epoch : 99 [78/79]| loss: 0.304 | acc: 92.550\n",
      "best test accuracy is  92.55\n",
      "train epoch : 100 [390/391]| loss: 0.030 | acc: 99.046\n",
      "test epoch : 100 [78/79]| loss: 0.302 | acc: 92.610\n",
      "best test accuracy is  92.61\n",
      "train epoch : 101 [390/391]| loss: 0.029 | acc: 99.078\n",
      "test epoch : 101 [78/79]| loss: 0.312 | acc: 92.440\n",
      "best test accuracy is  92.61\n",
      "train epoch : 102 [390/391]| loss: 0.027 | acc: 99.186\n",
      "test epoch : 102 [78/79]| loss: 0.316 | acc: 92.390\n",
      "best test accuracy is  92.61\n",
      "train epoch : 103 [390/391]| loss: 0.028 | acc: 99.118\n",
      "test epoch : 103 [78/79]| loss: 0.313 | acc: 92.540\n",
      "best test accuracy is  92.61\n",
      "train epoch : 104 [390/391]| loss: 0.025 | acc: 99.204\n",
      "test epoch : 104 [78/79]| loss: 0.318 | acc: 92.340\n",
      "best test accuracy is  92.61\n",
      "train epoch : 105 [390/391]| loss: 0.023 | acc: 99.292\n",
      "test epoch : 105 [78/79]| loss: 0.316 | acc: 92.250\n",
      "best test accuracy is  92.61\n",
      "train epoch : 106 [390/391]| loss: 0.024 | acc: 99.232\n",
      "test epoch : 106 [78/79]| loss: 0.322 | acc: 92.420\n",
      "best test accuracy is  92.61\n",
      "train epoch : 107 [390/391]| loss: 0.023 | acc: 99.348\n",
      "test epoch : 107 [78/79]| loss: 0.327 | acc: 92.200\n",
      "best test accuracy is  92.61\n",
      "train epoch : 108 [390/391]| loss: 0.022 | acc: 99.320\n",
      "test epoch : 108 [78/79]| loss: 0.320 | acc: 92.450\n",
      "best test accuracy is  92.61\n",
      "train epoch : 109 [390/391]| loss: 0.022 | acc: 99.312\n",
      "test epoch : 109 [78/79]| loss: 0.326 | acc: 92.450\n",
      "best test accuracy is  92.61\n",
      "train epoch : 110 [390/391]| loss: 0.021 | acc: 99.394\n",
      "test epoch : 110 [78/79]| loss: 0.323 | acc: 92.500\n",
      "best test accuracy is  92.61\n",
      "train epoch : 111 [390/391]| loss: 0.020 | acc: 99.438\n",
      "test epoch : 111 [78/79]| loss: 0.325 | acc: 92.490\n",
      "best test accuracy is  92.61\n",
      "train epoch : 112 [390/391]| loss: 0.020 | acc: 99.406\n",
      "test epoch : 112 [78/79]| loss: 0.325 | acc: 92.380\n",
      "best test accuracy is  92.61\n",
      "train epoch : 113 [390/391]| loss: 0.020 | acc: 99.382\n",
      "test epoch : 113 [78/79]| loss: 0.336 | acc: 92.410\n",
      "best test accuracy is  92.61\n",
      "train epoch : 114 [390/391]| loss: 0.018 | acc: 99.516\n",
      "test epoch : 114 [78/79]| loss: 0.333 | acc: 92.380\n",
      "best test accuracy is  92.61\n",
      "train epoch : 115 [390/391]| loss: 0.019 | acc: 99.430\n",
      "test epoch : 115 [78/79]| loss: 0.340 | acc: 92.570\n",
      "best test accuracy is  92.61\n",
      "train epoch : 116 [390/391]| loss: 0.019 | acc: 99.434\n",
      "test epoch : 116 [78/79]| loss: 0.338 | acc: 92.330\n",
      "best test accuracy is  92.61\n",
      "train epoch : 117 [390/391]| loss: 0.018 | acc: 99.468\n",
      "test epoch : 117 [78/79]| loss: 0.333 | acc: 92.570\n",
      "best test accuracy is  92.61\n",
      "train epoch : 118 [390/391]| loss: 0.018 | acc: 99.452\n",
      "test epoch : 118 [78/79]| loss: 0.341 | acc: 92.260\n",
      "best test accuracy is  92.61\n",
      "train epoch : 119 [390/391]| loss: 0.017 | acc: 99.532\n",
      "test epoch : 119 [78/79]| loss: 0.337 | acc: 92.460\n",
      "best test accuracy is  92.61\n",
      "train epoch : 120 [390/391]| loss: 0.016 | acc: 99.554\n",
      "test epoch : 120 [78/79]| loss: 0.345 | acc: 92.400\n",
      "best test accuracy is  92.61\n",
      "train epoch : 121 [390/391]| loss: 0.016 | acc: 99.554\n",
      "test epoch : 121 [78/79]| loss: 0.343 | acc: 92.400\n",
      "best test accuracy is  92.61\n",
      "train epoch : 122 [390/391]| loss: 0.015 | acc: 99.580\n",
      "test epoch : 122 [78/79]| loss: 0.345 | acc: 92.510\n",
      "best test accuracy is  92.61\n",
      "train epoch : 123 [390/391]| loss: 0.015 | acc: 99.552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 123 [78/79]| loss: 0.337 | acc: 92.350\n",
      "best test accuracy is  92.61\n",
      "train epoch : 124 [390/391]| loss: 0.013 | acc: 99.656\n",
      "test epoch : 124 [78/79]| loss: 0.335 | acc: 92.460\n",
      "best test accuracy is  92.61\n",
      "train epoch : 125 [390/391]| loss: 0.013 | acc: 99.632\n",
      "test epoch : 125 [78/79]| loss: 0.334 | acc: 92.480\n",
      "best test accuracy is  92.61\n",
      "train epoch : 126 [390/391]| loss: 0.013 | acc: 99.624\n",
      "test epoch : 126 [78/79]| loss: 0.333 | acc: 92.480\n",
      "best test accuracy is  92.61\n",
      "train epoch : 127 [390/391]| loss: 0.011 | acc: 99.710\n",
      "test epoch : 127 [78/79]| loss: 0.335 | acc: 92.530\n",
      "best test accuracy is  92.61\n",
      "train epoch : 128 [390/391]| loss: 0.011 | acc: 99.708\n",
      "test epoch : 128 [78/79]| loss: 0.337 | acc: 92.530\n",
      "best test accuracy is  92.61\n",
      "train epoch : 129 [390/391]| loss: 0.012 | acc: 99.698\n",
      "test epoch : 129 [78/79]| loss: 0.335 | acc: 92.470\n",
      "best test accuracy is  92.61\n",
      "train epoch : 130 [390/391]| loss: 0.012 | acc: 99.720\n",
      "test epoch : 130 [78/79]| loss: 0.331 | acc: 92.450\n",
      "best test accuracy is  92.61\n",
      "train epoch : 131 [390/391]| loss: 0.011 | acc: 99.706\n",
      "test epoch : 131 [78/79]| loss: 0.338 | acc: 92.400\n",
      "best test accuracy is  92.61\n",
      "train epoch : 132 [390/391]| loss: 0.011 | acc: 99.722\n",
      "test epoch : 132 [78/79]| loss: 0.336 | acc: 92.510\n",
      "best test accuracy is  92.61\n",
      "train epoch : 133 [390/391]| loss: 0.010 | acc: 99.772\n",
      "test epoch : 133 [78/79]| loss: 0.336 | acc: 92.580\n",
      "best test accuracy is  92.61\n",
      "train epoch : 134 [390/391]| loss: 0.010 | acc: 99.742\n",
      "test epoch : 134 [78/79]| loss: 0.338 | acc: 92.530\n",
      "best test accuracy is  92.61\n",
      "train epoch : 135 [390/391]| loss: 0.010 | acc: 99.756\n",
      "test epoch : 135 [78/79]| loss: 0.337 | acc: 92.530\n",
      "best test accuracy is  92.61\n",
      "train epoch : 136 [390/391]| loss: 0.010 | acc: 99.742\n",
      "test epoch : 136 [78/79]| loss: 0.337 | acc: 92.560\n",
      "best test accuracy is  92.61\n",
      "train epoch : 137 [390/391]| loss: 0.010 | acc: 99.746\n",
      "test epoch : 137 [78/79]| loss: 0.337 | acc: 92.590\n",
      "best test accuracy is  92.61\n",
      "train epoch : 138 [390/391]| loss: 0.010 | acc: 99.754\n",
      "test epoch : 138 [78/79]| loss: 0.336 | acc: 92.500\n",
      "best test accuracy is  92.61\n",
      "train epoch : 139 [390/391]| loss: 0.010 | acc: 99.774\n",
      "test epoch : 139 [78/79]| loss: 0.337 | acc: 92.480\n",
      "best test accuracy is  92.61\n",
      "train epoch : 140 [390/391]| loss: 0.010 | acc: 99.760\n",
      "test epoch : 140 [78/79]| loss: 0.337 | acc: 92.610\n",
      "best test accuracy is  92.61\n",
      "train epoch : 141 [390/391]| loss: 0.010 | acc: 99.792\n",
      "test epoch : 141 [78/79]| loss: 0.339 | acc: 92.580\n",
      "best test accuracy is  92.61\n",
      "train epoch : 142 [390/391]| loss: 0.010 | acc: 99.738\n",
      "test epoch : 142 [78/79]| loss: 0.337 | acc: 92.680\n",
      "best test accuracy is  92.68\n",
      "train epoch : 143 [390/391]| loss: 0.010 | acc: 99.766\n",
      "test epoch : 143 [78/79]| loss: 0.338 | acc: 92.670\n",
      "best test accuracy is  92.68\n",
      "train epoch : 144 [390/391]| loss: 0.010 | acc: 99.772\n",
      "test epoch : 144 [78/79]| loss: 0.337 | acc: 92.550\n",
      "best test accuracy is  92.68\n",
      "train epoch : 145 [390/391]| loss: 0.010 | acc: 99.754\n",
      "test epoch : 145 [78/79]| loss: 0.337 | acc: 92.600\n",
      "best test accuracy is  92.68\n",
      "train epoch : 146 [390/391]| loss: 0.010 | acc: 99.742\n",
      "test epoch : 146 [78/79]| loss: 0.336 | acc: 92.630\n",
      "best test accuracy is  92.68\n",
      "train epoch : 147 [390/391]| loss: 0.009 | acc: 99.786\n",
      "test epoch : 147 [78/79]| loss: 0.341 | acc: 92.530\n",
      "best test accuracy is  92.68\n",
      "train epoch : 148 [390/391]| loss: 0.010 | acc: 99.790\n",
      "test epoch : 148 [78/79]| loss: 0.340 | acc: 92.570\n",
      "best test accuracy is  92.68\n",
      "train epoch : 149 [390/391]| loss: 0.010 | acc: 99.738\n",
      "test epoch : 149 [78/79]| loss: 0.338 | acc: 92.640\n",
      "best test accuracy is  92.68\n",
      "train epoch : 150 [390/391]| loss: 0.009 | acc: 99.816\n",
      "test epoch : 150 [78/79]| loss: 0.340 | acc: 92.640\n",
      "best test accuracy is  92.68\n",
      "train epoch : 151 [390/391]| loss: 0.010 | acc: 99.768\n",
      "test epoch : 151 [78/79]| loss: 0.339 | acc: 92.780\n",
      "best test accuracy is  92.78\n",
      "train epoch : 152 [390/391]| loss: 0.010 | acc: 99.804\n",
      "test epoch : 152 [78/79]| loss: 0.341 | acc: 92.700\n",
      "best test accuracy is  92.78\n",
      "train epoch : 153 [390/391]| loss: 0.010 | acc: 99.752\n",
      "test epoch : 153 [78/79]| loss: 0.340 | acc: 92.610\n",
      "best test accuracy is  92.78\n",
      "train epoch : 154 [390/391]| loss: 0.009 | acc: 99.796\n",
      "test epoch : 154 [78/79]| loss: 0.341 | acc: 92.590\n",
      "best test accuracy is  92.78\n",
      "train epoch : 155 [390/391]| loss: 0.010 | acc: 99.782\n",
      "test epoch : 155 [78/79]| loss: 0.343 | acc: 92.560\n",
      "best test accuracy is  92.78\n",
      "train epoch : 156 [390/391]| loss: 0.009 | acc: 99.826\n",
      "test epoch : 156 [78/79]| loss: 0.340 | acc: 92.610\n",
      "best test accuracy is  92.78\n",
      "train epoch : 157 [390/391]| loss: 0.009 | acc: 99.784\n",
      "test epoch : 157 [78/79]| loss: 0.341 | acc: 92.550\n",
      "best test accuracy is  92.78\n",
      "train epoch : 158 [390/391]| loss: 0.010 | acc: 99.758\n",
      "test epoch : 158 [78/79]| loss: 0.341 | acc: 92.660\n",
      "best test accuracy is  92.78\n",
      "train epoch : 159 [390/391]| loss: 0.009 | acc: 99.836\n",
      "test epoch : 159 [78/79]| loss: 0.340 | acc: 92.780\n",
      "best test accuracy is  92.78\n",
      "train epoch : 160 [390/391]| loss: 0.009 | acc: 99.788\n",
      "test epoch : 160 [78/79]| loss: 0.343 | acc: 92.580\n",
      "best test accuracy is  92.78\n",
      "train epoch : 161 [390/391]| loss: 0.009 | acc: 99.772\n",
      "test epoch : 161 [78/79]| loss: 0.342 | acc: 92.660\n",
      "best test accuracy is  92.78\n",
      "train epoch : 162 [390/391]| loss: 0.009 | acc: 99.782\n",
      "test epoch : 162 [78/79]| loss: 0.340 | acc: 92.610\n",
      "best test accuracy is  92.78\n",
      "train epoch : 163 [390/391]| loss: 0.009 | acc: 99.820\n",
      "test epoch : 163 [78/79]| loss: 0.343 | acc: 92.640\n",
      "best test accuracy is  92.78\n",
      "train epoch : 164 [390/391]| loss: 0.008 | acc: 99.828\n",
      "test epoch : 164 [78/79]| loss: 0.346 | acc: 92.500\n",
      "best test accuracy is  92.78\n"
     ]
    }
   ],
   "source": [
    "block_32 = [\"16\", \"16\", \"16\", \"16\", \"16\", \"32P\", \"32\", \"32\", \"32\", \"32\", \"64P\", \"64\", \"64\", \"64\", \"64\"]\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "net = ResNet(block_cfg=block_32)\n",
    "net = net.to(device)\n",
    "num_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "print('The number of parameters of model is', num_params)\n",
    "# print(net)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, \n",
    "                      momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "decay_epoch = [32000, 48000]\n",
    "step_lr_scheduler = optim.lr_scheduler.MultiStepLR(optimizer, \n",
    "                                 milestones=decay_epoch, gamma=0.1)\n",
    "\n",
    "\n",
    "def train(epoch, global_steps):\n",
    "    net.train()\n",
    "\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        global_steps += 1\n",
    "        step_lr_scheduler.step()\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    acc = 100 * correct / total\n",
    "    print('train epoch : {} [{}/{}]| loss: {:.3f} | acc: {:.3f}'.format(\n",
    "           epoch, batch_idx, len(train_loader), train_loss/(batch_idx+1), acc))\n",
    "\n",
    "    return global_steps\n",
    "\n",
    "\n",
    "def test(epoch, best_acc, global_steps):\n",
    "    net.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    acc = 100 * correct / total\n",
    "    print('test epoch : {} [{}/{}]| loss: {:.3f} | acc: {:.3f}'.format(\n",
    "           epoch, batch_idx, len(test_loader), test_loss/(batch_idx+1), acc))\n",
    "\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "\n",
    "    return best_acc\n",
    "\n",
    "best_acc = 0\n",
    "epoch = 0\n",
    "global_steps = 0\n",
    "\n",
    "while True:\n",
    "    epoch += 1\n",
    "    global_steps = train(epoch, global_steps)\n",
    "    best_acc = test(epoch, best_acc, global_steps)\n",
    "    print('best test accuracy is ', best_acc)\n",
    "\n",
    "    if global_steps >= 64000:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.5\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "error_rates = []\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        error_rates.append(100 * (total - correct) / total)\n",
    "print(100 * correct / total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
